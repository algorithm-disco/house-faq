{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-4a721c3ed90c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mStratifiedKFold\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtqdm\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackend\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "from transformers import *\n",
    "print(tf.__version__)\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_left = pd.read_csv('./train/train.query.tsv',sep='\\t',header=None)\n",
    "train_left.columns=['id','query']\n",
    "train_right = pd.read_csv('./train/train.reply.tsv',sep='\\t',header=None)\n",
    "train_right.columns=['id','id_sub','reply','label']\n",
    "train_data = train_left.merge(train_right, how='left')\n",
    "train_data['reply'] = train_data['reply'].fillna('好的')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('./train/train.csv')\n",
    "# train_data['reply'] = train_data['reply'].fillna('好的')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>id_sub</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>0</td>\n",
       "      <td>杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>1</td>\n",
       "      <td>是的</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>2</td>\n",
       "      <td>这是5楼</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>因为公积金贷款贷的少</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>是呢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21580</th>\n",
       "      <td>5998</td>\n",
       "      <td>您好，我正在看尚林家园的房子</td>\n",
       "      <td>1</td>\n",
       "      <td>有啊</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>5998</td>\n",
       "      <td>您好，我正在看尚林家园的房子</td>\n",
       "      <td>2</td>\n",
       "      <td>我带你看看</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21582</th>\n",
       "      <td>5999</td>\n",
       "      <td>今天可以安排看房子吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>我约下房东，稍后回你</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>5999</td>\n",
       "      <td>今天可以安排看房子吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>可以看，你几点有时间过来呢？</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>5999</td>\n",
       "      <td>今天可以安排看房子吗？</td>\n",
       "      <td>2</td>\n",
       "      <td>好的，那咱们在一号门口这碰头？</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21585 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id           query  id_sub                        reply  label\n",
       "0         0        采荷一小是分校吧       0  杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。      1\n",
       "1         0        采荷一小是分校吧       1                           是的      0\n",
       "2         0        采荷一小是分校吧       2                         这是5楼      0\n",
       "3         1            毛坯吗？       0                   因为公积金贷款贷的少      0\n",
       "4         1            毛坯吗？       1                           是呢      0\n",
       "...     ...             ...     ...                          ...    ...\n",
       "21580  5998  您好，我正在看尚林家园的房子       1                           有啊      0\n",
       "21581  5998  您好，我正在看尚林家园的房子       2                        我带你看看      0\n",
       "21582  5999     今天可以安排看房子吗？       0                   我约下房东，稍后回你      1\n",
       "21583  5999     今天可以安排看房子吗？       1               可以看，你几点有时间过来呢？      1\n",
       "21584  5999     今天可以安排看房子吗？       2              好的，那咱们在一号门口这碰头？      0\n",
       "\n",
       "[21585 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_left = pd.read_csv('./train/train.query.tsv',sep='\\t',header=None)\n",
    "# train_left.columns=['id','q1']\n",
    "# train_right = pd.read_csv('./train/train.reply.tsv',sep='\\t',header=None)\n",
    "# train_right.columns=['id','id_sub','q2','label']\n",
    "# df_train = train_left.merge(train_right, how='left')\n",
    "# df_train['q2'] = df_train['q2'].fillna('好的')\n",
    "\n",
    "test_left = pd.read_csv('./test/test.query.tsv',sep='\\t',header=None, encoding='gbk')\n",
    "test_left.columns = ['id','query']\n",
    "test_right =  pd.read_csv('./test/test.reply.tsv',sep='\\t',header=None, encoding='gbk')\n",
    "test_right.columns=['id','id_sub','reply']\n",
    "df_test = test_left.merge(test_right, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>id_sub</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>东区西区？什么时候下证？</td>\n",
       "      <td>0</td>\n",
       "      <td>我在给你发套</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>东区西区？什么时候下证？</td>\n",
       "      <td>1</td>\n",
       "      <td>您看下我发的这几套</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>东区西区？什么时候下证？</td>\n",
       "      <td>2</td>\n",
       "      <td>这两套也是金源花园的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>东区西区？什么时候下证？</td>\n",
       "      <td>3</td>\n",
       "      <td>价钱低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>东区西区？什么时候下证？</td>\n",
       "      <td>4</td>\n",
       "      <td>便宜的房子，一般都是顶楼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53752</th>\n",
       "      <td>13998</td>\n",
       "      <td>这套房子有啥问题吗  我看价格不高</td>\n",
       "      <td>3</td>\n",
       "      <td>租约还有两年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53753</th>\n",
       "      <td>13998</td>\n",
       "      <td>这套房子有啥问题吗  我看价格不高</td>\n",
       "      <td>4</td>\n",
       "      <td>都有学位的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53754</th>\n",
       "      <td>13999</td>\n",
       "      <td>我看看时间吧</td>\n",
       "      <td>0</td>\n",
       "      <td>没有呢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53755</th>\n",
       "      <td>13999</td>\n",
       "      <td>我看看时间吧</td>\n",
       "      <td>1</td>\n",
       "      <td>今天新上的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53756</th>\n",
       "      <td>13999</td>\n",
       "      <td>我看看时间吧</td>\n",
       "      <td>2</td>\n",
       "      <td>房子我也没看过呢，不知道是几号楼</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id              query  id_sub             reply\n",
       "0          0       东区西区？什么时候下证？       0            我在给你发套\n",
       "1          0       东区西区？什么时候下证？       1         您看下我发的这几套\n",
       "2          0       东区西区？什么时候下证？       2        这两套也是金源花园的\n",
       "3          0       东区西区？什么时候下证？       3               价钱低\n",
       "4          0       东区西区？什么时候下证？       4      便宜的房子，一般都是顶楼\n",
       "...      ...                ...     ...               ...\n",
       "53752  13998  这套房子有啥问题吗  我看价格不高       3            租约还有两年\n",
       "53753  13998  这套房子有啥问题吗  我看价格不高       4             都有学位的\n",
       "53754  13999             我看看时间吧       0               没有呢\n",
       "53755  13999             我看看时间吧       1             今天新上的\n",
       "53756  13999             我看看时间吧       2  房子我也没看过呢，不知道是几号楼\n",
       "\n",
       "[53757 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (21585, 5)\n",
      "test shape = (53757, 4)\n"
     ]
    }
   ],
   "source": [
    "# * Validation loss before training: 0.6397, accuracy: 68.7500%, auc: 0.5097\n",
    "\n",
    "\n",
    "PATH = './'\n",
    "# BERT_PATH = './'\n",
    "# WEIGHT_PATH = './'\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "input_categories = ['query','reply']\n",
    "output_categories = 'label'\n",
    "\n",
    "print('train shape =', train_data.shape)\n",
    "print('test shape =', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_transformer_inputs(question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n",
    "    \n",
    "    def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "        inputs = tokenizer.encode_plus(str1, str2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=length,\n",
    "            truncation_strategy=truncation_strategy,\n",
    "            #truncation=True\n",
    "            )\n",
    "        \n",
    "        input_ids =  inputs[\"input_ids\"]\n",
    "        input_masks = [1] * len(input_ids)\n",
    "        input_segments = inputs[\"token_type_ids\"]\n",
    "        padding_length = length - len(input_ids)\n",
    "        padding_id = tokenizer.pad_token_id\n",
    "        input_ids = input_ids + ([padding_id] * padding_length)\n",
    "        input_masks = input_masks + ([0] * padding_length)\n",
    "        input_segments = input_segments + ([0] * padding_length)\n",
    "        \n",
    "        return [input_ids, input_masks, input_segments]\n",
    "    \n",
    "    input_ids_q, input_masks_q, input_segments_q = return_id(\n",
    "        question, answer, 'longest_first', max_sequence_length)\n",
    "    \n",
    "\n",
    "    \n",
    "    return [input_ids_q, input_masks_q, input_segments_q]\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids_q, input_masks_q, input_segments_q = [], [], []\n",
    "    input_ids_a, input_masks_a, input_segments_a = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        query,reply = instance.query, instance.reply\n",
    "\n",
    "        ids_q, masks_q, segments_q= \\\n",
    "        _convert_to_transformer_inputs(query, reply, tokenizer, max_sequence_length)\n",
    "        \n",
    "        input_ids_q.append(ids_q)\n",
    "        input_masks_q.append(masks_q)\n",
    "        input_segments_q.append(segments_q)\n",
    "\n",
    "    return [np.asarray(input_ids_q, dtype=np.int32), \n",
    "            np.asarray(input_masks_q, dtype=np.int32), \n",
    "            np.asarray(input_segments_q, dtype=np.int32)]\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "\n",
    "\n",
    "def search_f1(y_true, y_pred):\n",
    "    best = 0\n",
    "    best_t = 0\n",
    "    for i in range(30,60):\n",
    "        tres = i / 100\n",
    "        y_pred_bin =  (y_pred > tres).astype(int)\n",
    "        score = f1_score(y_true, y_pred_bin)\n",
    "        if score > best:\n",
    "            best = score\n",
    "            best_t = tres\n",
    "    print('best', best)\n",
    "    print('thres', best_t)\n",
    "    return best, best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21585it [00:12, 1784.46it/s]\n",
      "53757it [00:30, 1761.62it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./preTrainModel/bert_base_chinese_tf/bert-base-chinese-vocab.txt')\n",
    "outputs = compute_output_arrays(train_data, output_categories)\n",
    "inputs = compute_input_arrays(train_data, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    config = BertConfig.from_pretrained('./preTrainModel/bert_base_chinese_tf/bert-base-chinese-config.json') \n",
    "    config.output_hidden_states = False\n",
    "    bert_model = TFBertModel.from_pretrained('./preTrainModel/bert_base_chinese_tf/bert-base-chinese-tf_model.h5', \n",
    "                                             config=config)\n",
    "    q_embedding = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)[0]\n",
    "    q = tf.keras.layers.GlobalAveragePooling1D()(q_embedding)\n",
    "    a = tf.keras.layers.GlobalMaxPooling1D()(q_embedding)\n",
    "#     t = q_embedding[:,-1]\n",
    "#     e = q_embedding[:, 0]\n",
    "    x = tf.keras.layers.Concatenate()([q, a])\n",
    "    \n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn], outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "270/270 [==============================] - 236s 873ms/step - loss: 0.4435 - auc: 0.8201 - val_loss: 0.2981 - val_auc: 0.9225\n",
      "Epoch 2/3\n",
      "270/270 [==============================] - 243s 901ms/step - loss: 0.2880 - auc: 0.9294 - val_loss: 0.2727 - val_auc: 0.9337\n",
      "Epoch 3/3\n",
      "270/270 [==============================] - 237s 879ms/step - loss: 0.2176 - auc: 0.9605 - val_loss: 0.3233 - val_auc: 0.9364\n",
      "best 0.7736441057821605\n",
      "thres 0.58\n",
      "validation score =  0.7736441057821605\n",
      "Epoch 1/3\n",
      "270/270 [==============================] - 239s 885ms/step - loss: 0.4486 - auc: 0.8210 - val_loss: 0.3087 - val_auc: 0.9191\n",
      "Epoch 2/3\n",
      "270/270 [==============================] - 235s 869ms/step - loss: 0.3042 - auc: 0.9222 - val_loss: 0.3008 - val_auc: 0.9330\n",
      "Epoch 3/3\n",
      "270/270 [==============================] - 237s 877ms/step - loss: 0.2445 - auc: 0.9505 - val_loss: 0.3025 - val_auc: 0.9296\n",
      "best 0.7718978102189782\n",
      "thres 0.3\n",
      "validation score =  0.7718978102189782\n",
      "Epoch 1/3\n",
      "270/270 [==============================] - 255s 944ms/step - loss: 0.3910 - auc: 0.8561 - val_loss: 0.3102 - val_auc: 0.9284\n",
      "Epoch 2/3\n",
      "270/270 [==============================] - 253s 938ms/step - loss: 0.2569 - auc: 0.9431 - val_loss: 0.2753 - val_auc: 0.9400\n",
      "Epoch 3/3\n",
      "270/270 [==============================] - 254s 941ms/step - loss: 0.1866 - auc: 0.9702 - val_loss: 0.3027 - val_auc: 0.9328\n",
      "best 0.7816387816387816\n",
      "thres 0.38\n",
      "validation score =  0.7816387816387816\n",
      "Epoch 1/3\n",
      "270/270 [==============================] - 270s 999ms/step - loss: 0.4086 - auc: 0.8485 - val_loss: 0.2710 - val_auc: 0.9357\n",
      "Epoch 2/3\n",
      "270/270 [==============================] - 270s 1s/step - loss: 0.2683 - auc: 0.9392 - val_loss: 0.2694 - val_auc: 0.9406\n",
      "Epoch 3/3\n",
      "270/270 [==============================] - 265s 983ms/step - loss: 0.1941 - auc: 0.9683 - val_loss: 0.3009 - val_auc: 0.9349\n",
      "best 0.785451197053407\n",
      "thres 0.43\n",
      "validation score =  0.785451197053407\n",
      "Epoch 1/3\n",
      "270/270 [==============================] - 257s 952ms/step - loss: 0.4034 - auc: 0.8489 - val_loss: 0.3163 - val_auc: 0.9181\n",
      "Epoch 2/3\n",
      "270/270 [==============================] - 250s 927ms/step - loss: 0.2678 - auc: 0.9386 - val_loss: 0.2964 - val_auc: 0.9299\n",
      "Epoch 3/3\n",
      "270/270 [==============================] - 242s 898ms/step - loss: 0.1996 - auc: 0.9656 - val_loss: 0.3148 - val_auc: 0.9294\n",
      "best 0.768\n",
      "thres 0.3\n",
      "validation score =  0.768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gkf = GroupKFold(n_splits=5).split(X=train_data.reply, groups=train_data.id)\n",
    "\n",
    "valid_preds = []\n",
    "test_preds = []\n",
    "\n",
    "oof = np.zeros((len(train_data),1))\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n",
    "    train_outputs = outputs[train_idx]\n",
    "    valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
    "    valid_outputs = outputs[valid_idx]\n",
    "\n",
    "    K.clear_session()\n",
    "    model = create_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[tf.keras.metrics.AUC()])\n",
    "    model.fit(train_inputs, train_outputs, validation_data = (valid_inputs, valid_outputs), epochs=3, batch_size=64)\n",
    "    oof_p = model.predict(valid_inputs, batch_size=512)\n",
    "    oof[valid_idx] = oof_p\n",
    "    valid_preds.append(oof_p)\n",
    "    test_preds.append(model.predict(test_inputs, batch_size=512))\n",
    "    f1,t = search_f1(valid_outputs, valid_preds[-1])\n",
    "    print('validation score = ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best 0.7701951090315176\n",
      "thres 0.33\n"
     ]
    }
   ],
   "source": [
    "best_score, best_t = search_f1(outputs,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.average(test_preds, axis=0) \n",
    "sub = sub > best_t\n",
    "df_test['label'] = sub.astype(int)\n",
    "df_test[['id','id_sub','label']].to_csv('./submission_file/submission_beike_bert_base_enhancedata.csv',index=False, header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}